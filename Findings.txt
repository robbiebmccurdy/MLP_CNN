MLP
	MLP1.

		Accuracy: 

			Accuracy of the network on the 10000 test images: 50 %
			Accuracy for class: plane is 57.4 %
			Accuracy for class: car   is 59.9 %
			Accuracy for class: bird  is 35.6 %
			Accuracy for class: cat   is 23.7 %
			Accuracy for class: deer  is 54.4 %
			Accuracy for class: dog   is 41.8 %
			Accuracy for class: frog  is 57.4 %
			Accuracy for class: horse is 56.6 %
			Accuracy for class: ship  is 64.2 %
			Accuracy for class: truck is 55.4 %

		Seems to be a toss-up on whether or not the model can determine things overall. However, upon individual inspection, it seems as though we are
		doing fairly well with finding cars, planes, and ships. The reverse of this though, we are doing extremely poor finding cats and birds. Ideally
		we'd like these numbers to be close to 70% but that may be too optimistic for this model/project. So we will shoot for hopefully an overall
		network accuracy of ~60%.

	MLP2.
		In the MLP model for the CIFAR-10 dataset, incorporating a validation step significantly enhances training effectiveness. Through regular validation checks after each training epoch, I can pinpoint the ideal moment to halt training, helping to prevent overfitting. This is evident when the model performs increasingly well on training data but starts faltering on validation data.

		Moreover, validation insights are key in fine-tuning hyperparameters and adjusting the model's architecture. If the model underperforms on the validation set, it suggests a need for modificationsâ€”perhaps a more complex structure or extended training. Conversely, a pronounced gap between training and validation performance could indicate overfitting, necessitating the introduction of regularization methods. Ultimately, this approach ensures the model's robust generalization, preparing it for effective real-world application.

		Taking this cross-validation into account, our overall accuracy rose to 51% meanwhile many classes rose as well. Most notably, ships rose from 64.2% to 71.1% but a class like deer fell from 54.4% to 42.4% overall.

	MLP3.
		First, to address the accuracy measure, we can try to increase the amount of epochs we iterate against to train our data. I will be increasing the amount of epochs from 12 to 25. Below will be the updated accuracies of 25 epochs. 

		Accuracy of 25 epochs:
			Accuracy of the network on the 10000 test images: 50 %
			Accuracy for class: plane is 53.1 %
			Accuracy for class: car   is 58.8 %
			Accuracy for class: bird  is 29.4 %
			Accuracy for class: cat   is 33.3 %
			Accuracy for class: deer  is 43.5 %
			Accuracy for class: dog   is 41.6 %
			Accuracy for class: frog  is 60.5 %
			Accuracy for class: horse is 59.1 %
			Accuracy for class: ship  is 68.5 %
			Accuracy for class: truck is 55.3 %	

		It seems increasing our epochs from 12 to 25 did very little, if not it seems the overall validation performed slightly worse but essentially the same. A great thing is that a class like cat has gone up in accuracy, but itseems classes around it have either stagnated or fallen.

		Next, I will try adjusting the learning rate. To keep these fair, I will return epochs to 12 instead of 25. Then once we weight what changes the most, at the end I will implement all methods deemed valuable and check their accuracies.

		Accuracy for 5e-4 learning rate: 

			Accuracy of the network on the 10000 test images: 48 %
			Accuracy for class: plane is 48.9 %
			Accuracy for class: car   is 50.8 %
			Accuracy for class: bird  is 35.4 %
			Accuracy for class: cat   is 31.0 %
			Accuracy for class: deer  is 42.0 %
			Accuracy for class: dog   is 44.1 %
			Accuracy for class: frog  is 56.7 %
			Accuracy for class: horse is 52.3 %
			Accuracy for class: ship  is 73.7 %
			Accuracy for class: truck is 53.7 %

		With an updated learning rate, it seems like our overall accuracy has decreased, but upon closer inspection I'd say it seems that our lower end of accuracy has actually improved. The parts that have decreased are mostly all other fields except for ship which has rose to 73.7%. This indicates that potentially learning rate could drive accuracy up, but th is learning rate may be far too great.

		I've tested the learning rates 0.5e-4 and 2.5e-4 as well, and it seems like this value does have an effect but the best overall accuracy has been achieved with 1e-4. The learning rate will be reverted to 1e-4 and another method will be implemented.

CNN
	CNN1.

	CNN2.

	CNN3.

CC
	CC1.

PB
	PB1.

	PB2.

	PB3.

	PB4.